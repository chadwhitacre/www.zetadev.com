<!--#include file="inc/head.html" -->
<h1>Introduction</h1>

<p>Consider these contrived Python functions:</p>

<pre>
def copy_concat(s):
    """Copy a string via concatenation.
    """
    t = ""
    for c in s:
        t += c
    return t

def copy_join(s):
    """Copy a string via list joining.
    """
    t = []
    for c in s:
        t.append(c)
    return ''.join(t)
</pre>

<p>Both take a string and return a copy of it, but which one is faster? The
second, as any Python programmer knows. How much faster? That is the question
that <em>big O notation</em> exists to answer.</p>

<p>Big O notation is a way to talk about how efficient your programs are. Its
roots are in math, but it entered computer science proper with <a
href="http://portal.acm.org/citation.cfm?doid=1008328.1008329">a 1976 article by
Donald Knuth</a> (the 'O' is actually an omicron). The idea is to estimate how
your program's CPU and memory requirements will change as the size of its input
changes. For example, let's say we have a function that requires 1 second of CPU
time and 11 kB of memory to process 10 kB of data. Then let's say we feed it 100
kB of data. Does it still take 1 second but now use 101 kB of memory? Or does it
still use 11 kB of memory but now take 10 seconds? Or what?</p>

<p>Notice how our time (CPU) and space (memory) requirements are inversely
related: in programming you always have to choose between a fast program and a
small one. Big O notation helps in both cases, because it looks at how resource
requirements grow as inputs grow, regardless of the specific resource. CPU time
and memory are the resources you are usually concerned with, but big O notation
can also help you analyse your usage of disk space, bandwidth, rock, paper,
scissors, etc.</p>

<p>So if we class algorithms according to their efficiency for a given resource,
we find <a
href="http://en.wikipedia.org/wiki/Big_O_notation#Common_orders_of_functions">twelve
common cases</a>. Here they are, listed in order of decreasing efficiency, with
their common names and their big O notations:</p>

<table id="O">
  <tr><th colspan="3"><center>Classes of Algorithm by Efficiency</center></th></tr>
  <tr><th>&nbsp;</th><th>Name</th><th>Big O Notation</th></tr>
  <tr><td class="num">1.</td><td>constant</td><td>O(1)</td></tr>
  <tr><td class="num">2.</td><td>iterated logarithmic</td><td>O(log* n)</td></tr>
  <tr><td class="num">3.</td><td>logarithmic</td><td>O(log n)</td></tr>
  <tr><td class="num">4.</td><td>polylogarithmic</td><td>O((log n)<sup>c</sup>)</td></tr>
  <tr><td class="num">5.</td><td>fractional power</td><td>O(n<sup>c</sup>), 0<c<1</td></tr>
  <tr><td class="num">6.</td><td>linear</td><td>O(n)</td></tr>
  <tr><td class="num">7.</td><td>linearithmic, loglinear, or quasilinear</td><td>O(n log n)</td></tr>
  <tr><td class="num">8.</td><td>quadratic</td><td>O(n<sup>2</sup>)</td></tr>
  <tr><td class="num">9.</td><td>polynomial, or algebraic</td><td>O(n<sup>c</sup>), c>1</td></tr>
  <tr><td class="num">10.</td><td>exponential, or geometric</td><td>O(c<sup>n</sup>)</td></tr>
  <tr><td class="num">11.</td><td>factorial, or combinatorial</td><td>O(n!)</td></tr>
  <tr><td class="num">12.</td><td>double exponential</td><td>O(2<sup>c<sup>n</sup></sup>)</td></tr>
</table>

<p>We might say of a particular algorithm, then, that it is "constant with
regard to time:" no matter how much data you throw at it, it always finishes in
the same amount of time. Of another we might say that it is "oh en squared with
regard to memory" (quadratic): feeding it twice the data takes up four times the
memory, and feeding it four times the data takes up sixteen times the memory.
Armed with these estimates, we can then compare one algorithm to another, and
make an informed choice between them based on the resource constraints we bring
to the problem.</p>

<p>The rest of this article consists of examples illustrating the most common of
these classes. Our examples come from <a
href="http://en.wikipedia.org/wiki/Big_O_notation#Common_orders_of_functions">the
Wikipedia article</a>, which all take time as the resource of interest, but
again, this kind of analysis can apply to any resource.</p>

<p class="continue"><a href="01-constant.shtml#start">Continue to <i>Constant:
O(1)</i> &rArr;</a></p>

<!--#include file="inc/tail.html" -->